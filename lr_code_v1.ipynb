{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dbcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding = 'utf-8'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('no_missing_data.csv', header=0, encoding='utf-8')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f49f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4833, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96149194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Indices of the two rows to swap\n",
    "index1, index2 = 14, 0\n",
    "\n",
    "# Perform the swap\n",
    "df.loc[index1], df.loc[index2] = df.loc[index2].copy(), df.loc[index1].copy()\n",
    "\n",
    "# Drop columns that are not needed\n",
    "columns_to_drop = ['StudentNumber', 'useraccount_id', 'SchoolName', 'AlgScaleScore']\n",
    "df = df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Define variable types\n",
    "binary_variables = ['Sex', 'FRL_Status', 'Race_Indicator', 'Hispanic_Indicator', 'RetakerFlag']\n",
    "nominal_variables = ['SchoolNumber']\n",
    "continuous_variables = ['FSAMath_2018_AchievementLevel', 'TotalNumberofAbsences', \n",
    "                        'sum_session', 'video_id', 'total_video_time', 'video_completed', 'video_pause', 'video_play', 'video_seek', 'avg_user_gave_correct_answer', \n",
    "                        'tys_finish', 'tys_previous', 'tys_review_incorrect_question', 'tys_review_solution_video', 'wall_page_load']\n",
    "\n",
    "# Create a preprocessor for the continuous variables\n",
    "continuous_preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values using the mean\n",
    "    ('scaler', StandardScaler())  # Standardize features by removing the mean and scaling to unit variance\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', continuous_preprocessor, continuous_variables),\n",
    "        # ('cat', OneHotEncoder(handle_unknown='ignore'), nominal_variables)  # Uncomment and adjust if categorical processing is needed\n",
    "    ])\n",
    "\n",
    "# Define a logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)  # Increase the number of iterations to ensure convergence\n",
    "\n",
    "# Create a complete pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Apply the preprocessing steps\n",
    "    ('classifier', logistic_model)  # Use logistic regression as the classifier\n",
    "])\n",
    "\n",
    "# Select columns to keep for the model input\n",
    "columns_to_keep = binary_variables + nominal_variables + continuous_variables\n",
    "\n",
    "# Filter the DataFrame to only the necessary columns\n",
    "X = df[columns_to_keep]\n",
    "\n",
    "# Assume 'risk' is the target variable\n",
    "y = df['risk']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a30a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_to_keep + ['risk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf7dc8",
   "metadata": {},
   "source": [
    "### LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6ed60ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9370f5eed0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2feed5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4833, 25)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[columns_to_keep + ['risk']]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91c8a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RetakerFlag</th>\n",
       "      <th>FRL_Status</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race_Indicator</th>\n",
       "      <th>Hispanic_Indicator</th>\n",
       "      <th>SchoolNumber</th>\n",
       "      <th>TotalNumberofAbsences</th>\n",
       "      <th>FSAMath_2018_AchievementLevel</th>\n",
       "      <th>FSAMath_2018_ScaleScore</th>\n",
       "      <th>sum_session</th>\n",
       "      <th>...</th>\n",
       "      <th>video_pause</th>\n",
       "      <th>video_play</th>\n",
       "      <th>video_seek</th>\n",
       "      <th>avg_user_gave_correct_answer</th>\n",
       "      <th>tys_finish</th>\n",
       "      <th>tys_previous</th>\n",
       "      <th>tys_review_incorrect_question</th>\n",
       "      <th>tys_review_solution_video</th>\n",
       "      <th>wall_page_load</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>298.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1681</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3971</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>176.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1451</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RetakerFlag  FRL_Status  Sex  Race_Indicator  Hispanic_Indicator  \\\n",
       "0            0           1    1             1.0                   1   \n",
       "1            0           1    0             1.0                   0   \n",
       "2            0           0    1             1.0                   1   \n",
       "3            0           1    0             1.0                   0   \n",
       "4            0           1    0             1.0                   0   \n",
       "\n",
       "   SchoolNumber  TotalNumberofAbsences  FSAMath_2018_AchievementLevel  \\\n",
       "0           251                      5                            2.0   \n",
       "1          1681                      2                            3.0   \n",
       "2          3971                      5                            4.0   \n",
       "3           171                      7                            1.0   \n",
       "4          1451                      8                            3.0   \n",
       "\n",
       "   FSAMath_2018_ScaleScore  sum_session  ...  video_pause  video_play  \\\n",
       "0                    328.0         20.0  ...        298.0       272.0   \n",
       "1                    349.0         10.0  ...         60.0        58.0   \n",
       "2                    359.0         10.0  ...        352.0       294.0   \n",
       "3                    307.0         20.0  ...        176.0       173.0   \n",
       "4                    346.0         40.0  ...        331.0       378.0   \n",
       "\n",
       "   video_seek  avg_user_gave_correct_answer  tys_finish  tys_previous  \\\n",
       "0       608.0                          0.10        69.0          14.0   \n",
       "1       120.0                          0.10         0.0           0.0   \n",
       "2      3878.0                          0.70         0.0           0.0   \n",
       "3        72.0                          0.10         3.0           7.0   \n",
       "4       335.0                          0.35        11.0           0.0   \n",
       "\n",
       "   tys_review_incorrect_question  tys_review_solution_video  wall_page_load  \\\n",
       "0                           92.0                        1.0            54.0   \n",
       "1                            0.0                        0.0             3.0   \n",
       "2                            0.0                        0.0            16.0   \n",
       "3                            5.0                        0.0            43.0   \n",
       "4                            9.0                       20.0            40.0   \n",
       "\n",
       "   risk  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcb3f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('risk',1)\n",
    "y = data[['risk']]\n",
    "\n",
    "X = torch.tensor(np.array(X)).float()\n",
    "y = torch.tensor(np.array(y).flatten()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Splitting the dataset\n",
    "train_size = int(num_samples * 0.8)  # 80% of the dataset is used for training\n",
    "test_size = num_samples - train_size  # Remaining 20% is used for testing\n",
    "train_dataset = TensorDataset(X[:train_size], y[:train_size])  # Creating the training dataset\n",
    "test_dataset = TensorDataset(X[train_size:], y[train_size:])  # Creating the testing dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # DataLoader for the training dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # DataLoader for the testing dataset\n",
    "\n",
    "# Define a logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Linear layer that outputs to one unit, expecting sigmoid activation for binary classification\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applying the sigmoid function to the output of the linear layer\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "# Initialize the model with the number of features\n",
    "model = LogisticRegressionModel(num_features)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10  # Number of training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for this training step\n",
    "        outputs = model(inputs)  # Forward pass to get output\n",
    "        loss = criterion(outputs, labels.view(-1, 1))  # Calculate loss\n",
    "        loss.backward()  # Getting gradients w.r.t. parameters\n",
    "        optimizer.step()  # Updating parameters\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()  # Sets the model to evaluation mode\n",
    "with torch.no_grad():  # Gradient computation is disabled since the model is being evaluated\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)  # Compute model output\n",
    "        predicted = (outputs.data > 0.5).float()  # Convert output probabilities to binary predictions\n",
    "        total += labels.size(0)  # Total number of labels\n",
    "        correct += (predicted.view(-1) == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy}%')  # Print the accuracy in percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "y_true = []  # List to store actual labels\n",
    "y_pred = []  # List to store predicted labels\n",
    "\n",
    "# Disable gradient computation to speed up the process and reduce memory usage\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:  # Iterate through the test dataset\n",
    "        outputs = model(inputs)  # Forward pass: compute the output of the model\n",
    "        predicted = (outputs.data > 0.5).float().view(-1)  # Apply threshold to get binary predictions\n",
    "        y_true.extend(labels.tolist())  # Extend the list of actual labels\n",
    "        y_pred.extend(predicted.tolist())  # Extend the list of predictions\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)  # Calculate the accuracy\n",
    "precision = precision_score(y_true, y_pred)  # Calculate the precision\n",
    "recall = recall_score(y_true, y_pred)  # Calculate the recall\n",
    "f1 = f1_score(y_true, y_pred)  # Calculate the F1 score\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01387a",
   "metadata": {},
   "source": [
    "### LR with TE constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00473820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['FRL_Status', 'Sex', 'Race_Indicator', 'Hispanic_Indicator'] 这几个特征在的位置为1,2,3,4,所以索引列表为[1,2,3,4]\n",
    "sensitive_feature_indices = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09a72ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Define a linear layer with input dimension to 1 output (binary classification)\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the sigmoid activation function to the linear layer's output\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "# Instantiate the model with the number of features\n",
    "model = LogisticRegressionModel(num_features)\n",
    "\n",
    "# Define a custom loss function\n",
    "def custom_loss(outputs, labels, inputs, lambda_fairness=0.01):\n",
    "    # Basic loss: binary cross-entropy\n",
    "    criterion = nn.BCELoss()\n",
    "    loss = criterion(outputs, labels.view(-1, 1))\n",
    "\n",
    "    # Add fairness loss\n",
    "    fairness_loss = 0\n",
    "    # Calculate fairness metric for each sensitive feature index\n",
    "    for idx in sensitive_feature_indices:\n",
    "        fairness_loss += calculate_group_fairness_metric(outputs, labels, inputs[:, idx])\n",
    "    # Total loss includes both basic and fairness-induced losses\n",
    "    total_loss = loss + lambda_fairness * fairness_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def calculate_group_fairness_metric(outputs, labels, sensitive_feature):\n",
    "    epsilon = 1e-6  # A small constant to prevent division by zero\n",
    "\n",
    "    # Split data into two groups based on sensitive feature\n",
    "    group_0 = (sensitive_feature == 0)\n",
    "    group_1 = (sensitive_feature == 1)\n",
    "\n",
    "    # Compute False Positive Rate (FPR) and False Negative Rate (FNR) for each group\n",
    "    fpr_0 = torch.mean(outputs[group_0 & (labels == 0)]) if group_0.any() and (labels[group_0] == 0).any() else torch.tensor(0.0)\n",
    "    fnr_0 = torch.mean(1 - outputs[group_0 & (labels == 1)]) if group_0.any() and (labels[group_0] == 1).any() else torch.tensor(0.0)\n",
    "    fpr_1 = torch.mean(outputs[group_1 & (labels == 0)]) if group_1.any() and (labels[group_1] == 0).any() else torch.tensor(0.0)\n",
    "    fnr_1 = torch.mean(1 - outputs[group_1 & (labels == 1)]) if group_1.any() and (labels[group_1] == 1).any() else torch.tensor(0.0)\n",
    "\n",
    "    # Calculate a fairness metric based on FPR and FNR\n",
    "    return torch.abs(fnr_0 * fpr_1/(fpr_0 * fnr_1 + epsilon)-1)\n",
    "\n",
    "# Set up the optimizer with Adam algorithm and a learning rate of 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(inputs)\n",
    "        # Calculate loss\n",
    "        loss = custom_loss(outputs, labels, inputs)\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ec10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.view(-1) == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_treatment_equality(y_true, y_pred, groups):\n",
    "    epsilon = 1e-6\n",
    "    treatment_equality_diff = []\n",
    "\n",
    "    # Assuming that 'groups' contains the same keys as in the original example: 'FRL_Status', 'Sex', 'Race_Indicator', 'Hispanic_Indicator'\n",
    "    for g in np.unique(groups):\n",
    "        # Filter the predictions and labels for each group\n",
    "        idx_group_0 = groups == 0\n",
    "        idx_group_1 = groups == 1\n",
    "\n",
    "        y_true_g0 = y_true[idx_group_0]\n",
    "        y_pred_g0 = y_pred[idx_group_0]\n",
    "        y_true_g1 = y_true[idx_group_1]\n",
    "        y_pred_g1 = y_pred[idx_group_1]\n",
    "\n",
    "        # Compute False Negative Rate (FNR) and False Positive Rate (FPR)\n",
    "        fnr_group_0 = np.mean((y_pred_g0 == 0) & (y_true_g0 == 1))\n",
    "        fpr_group_0 = np.mean((y_pred_g0 == 1) & (y_true_g0 == 0))\n",
    "        fnr_group_1 = np.mean((y_pred_g1 == 0) & (y_true_g1 == 1))\n",
    "        fpr_group_1 = np.mean((y_pred_g1 == 1) & (y_true_g1 == 0))\n",
    "\n",
    "        # Compute the treatment equality difference using the specified formula\n",
    "        diff = abs(fnr_group_0 * fnr_group_1 / (fpr_group_0 * fpr_group_1 + epsilon))\n",
    "        treatment_equality_diff.append(diff)\n",
    "\n",
    "    # Calculate the average difference across all features\n",
    "    overall_te = np.mean(treatment_equality_diff) if treatment_equality_diff else 0\n",
    "    return overall_te\n",
    "\n",
    "# Example usage in a PyTorch evaluation context\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "groups = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, group in test_loader:  # Assume group information is also loaded\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.data > 0.5).float().view(-1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "        groups.extend(group.numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for easier manipulation\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "groups = np.array(groups)\n",
    "\n",
    "# Calculate Treatment Equality\n",
    "treatment_equality = calculate_treatment_equality(y_true, y_pred, groups)\n",
    "print(f'Treatment Equality: {treatment_equality}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
